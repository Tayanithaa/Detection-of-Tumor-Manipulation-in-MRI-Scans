{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "702b15f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\DeepFake_Tumor\\Detection-of-Tumor-Manipulation-in-MRI-Scans\\venv\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc1da57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1582582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Processed', 'Raw']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(\"Dataset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f61fa16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW PATH: c:\\Projects\\DeepFake_Tumor\\Detection-of-Tumor-Manipulation-in-MRI-Scans\\Dataset\\Raw\n",
      "PROCESSED PATH: c:\\Projects\\DeepFake_Tumor\\Detection-of-Tumor-Manipulation-in-MRI-Scans\\Dataset\\Processed\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "BASE_DIR = os.getcwd()\n",
    "\n",
    "RAW_PATH = os.path.join(BASE_DIR, \"Dataset\", \"Raw\")\n",
    "PROCESSED_PATH = os.path.join(BASE_DIR, \"Dataset\", \"Processed\")\n",
    "\n",
    "print(\"RAW PATH:\", RAW_PATH)\n",
    "print(\"PROCESSED PATH:\", PROCESSED_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f70fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Testing', 'Training']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(RAW_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "58a73db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_random_patch(img):\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    center_x = w // 2\n",
    "    center_y = h // 2\n",
    "    radius = random.randint(20, 40)\n",
    "\n",
    "    mask = np.zeros((h, w), dtype=np.uint8)\n",
    "    cv2.circle(mask, (center_x, center_y), radius, 255, -1)\n",
    "\n",
    "    patch = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    return patch, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e368c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_patch(target_img, patch, mask):\n",
    "    h, w = target_img.shape[:2]\n",
    "\n",
    "    x_offset = random.randint(30, w - 30)\n",
    "    y_offset = random.randint(30, h - 30)\n",
    "\n",
    "    # Smooth mask edges\n",
    "    smooth_mask = cv2.GaussianBlur(mask, (31, 31), 0)\n",
    "\n",
    "    for c in range(3):\n",
    "        target_img[:, :, c] = np.where(\n",
    "            smooth_mask > 0,\n",
    "            patch[:, :, c],\n",
    "            target_img[:, :, c]\n",
    "        )\n",
    "\n",
    "    return target_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b6a7f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_deepfake(split_type):\n",
    "    print(f\"\\nGenerating deepfake for {split_type} set...\")\n",
    "\n",
    "    raw_split_path = os.path.join(RAW_PATH, split_type)\n",
    "    processed_split_path = os.path.join(PROCESSED_PATH, split_type.lower())\n",
    "\n",
    "    real_output = os.path.join(processed_split_path, \"real\")\n",
    "    fake_output = os.path.join(processed_split_path, \"manipulated\")\n",
    "\n",
    "    os.makedirs(real_output, exist_ok=True)\n",
    "    os.makedirs(fake_output, exist_ok=True)\n",
    "\n",
    "    tumor_images = []\n",
    "    for cls in tumor_classes:\n",
    "        class_path = os.path.join(raw_split_path, cls)\n",
    "        for file in os.listdir(class_path):\n",
    "            tumor_images.append(os.path.join(class_path, file))\n",
    "\n",
    "    non_tumor_path = os.path.join(raw_split_path, non_tumor_class)\n",
    "    non_tumor_images = os.listdir(non_tumor_path)\n",
    "\n",
    "    for i in tqdm(range(len(non_tumor_images))):\n",
    "        non_tumor_img_path = os.path.join(non_tumor_path, non_tumor_images[i])\n",
    "        non_tumor_img = cv2.imread(non_tumor_img_path)\n",
    "\n",
    "        if non_tumor_img is None:\n",
    "            continue\n",
    "\n",
    "        tumor_img_path = random.choice(tumor_images)\n",
    "        tumor_img = cv2.imread(tumor_img_path)\n",
    "\n",
    "        if tumor_img is None:\n",
    "            continue\n",
    "\n",
    "        non_tumor_img = cv2.resize(non_tumor_img, (224, 224))\n",
    "        tumor_img = cv2.resize(tumor_img, (224, 224))\n",
    "\n",
    "        patch, mask = extract_random_patch(tumor_img)\n",
    "        deepfake_img = insert_patch(non_tumor_img.copy(), patch, mask)\n",
    "\n",
    "        cv2.imwrite(os.path.join(real_output, f\"real_{i}.jpg\"), non_tumor_img)\n",
    "        cv2.imwrite(os.path.join(fake_output, f\"deepfake_{i}.jpg\"), deepfake_img)\n",
    "\n",
    "    print(f\"Deepfake generation completed for {split_type}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a02e91ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\DeepFake_Tumor\\Detection-of-Tumor-Manipulation-in-MRI-Scans\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b108b56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating deepfake for Training set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [00:35<00:00, 39.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepfake generation completed for Training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_deepfake(\"Training\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b22a739f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating deepfake for Testing set...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:09<00:00, 41.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deepfake generation completed for Testing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generate_deepfake(\"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf864dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['manipulated', 'real']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5], [0.5])\n",
    "])\n",
    "\n",
    "train_dir = \"Dataset/Processed/train\"\n",
    "test_dir = \"Dataset/Processed/test\"\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False, num_workers=0)\n",
    "\n",
    "print(\"Classes:\", train_dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09c5e0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Ready on: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(weights=\"IMAGENET1K_V1\")\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.0001)\n",
    "\n",
    "print(\"Model Ready on:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a7c026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [02:46<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7106098677856582\n",
      "Train Accuracy: 50.99107142857143\n",
      "\n",
      "Epoch [2/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:19<00:00, 17.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6950577895343304\n",
      "Train Accuracy: 52.357142857142854\n",
      "\n",
      "Epoch [3/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:11<00:00, 19.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6843460759307657\n",
      "Train Accuracy: 54.642857142857146\n",
      "\n",
      "Epoch [4/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:11<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6832602891325951\n",
      "Train Accuracy: 55.214285714285715\n",
      "\n",
      "Epoch [5/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:08<00:00, 20.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6813637605096613\n",
      "Train Accuracy: 54.82142857142857\n",
      "\n",
      "Epoch [6/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:06<00:00, 20.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6796013249031135\n",
      "Train Accuracy: 54.598214285714285\n",
      "\n",
      "Epoch [7/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:10<00:00, 19.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6783006712368557\n",
      "Train Accuracy: 55.535714285714285\n",
      "\n",
      "Epoch [8/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:13<00:00, 18.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6788155511447361\n",
      "Train Accuracy: 55.276785714285715\n",
      "\n",
      "Epoch [9/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:12<00:00, 19.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6774646435252257\n",
      "Train Accuracy: 55.267857142857146\n",
      "\n",
      "Epoch [10/10]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [01:11<00:00, 19.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6767677692643234\n",
      "Train Accuracy: 55.482142857142854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}]\")\n",
    "\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(\"Loss:\", running_loss / len(train_loader))\n",
    "    print(\"Train Accuracy:\", 100 * correct / total)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
